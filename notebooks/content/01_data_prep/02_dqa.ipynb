{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if 'jbook' in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x7f0aa895eec0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from importlib import reload  # Not needed in Python 2\n",
    "# import logging\n",
    "# reload(logging)\n",
    "# logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')\n",
    "import dask\n",
    "dask.config.set({'logging.distributed': 'error'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Assessment\n",
    "The second stage of data processing is the Data Quality Assessment. This stage ensures that our dataset is ready for subsequent analysis and modeling tasks. By identifying and rectifying data quality issues early, we can avoid potential pitfalls that might compromise the integrity and accuracy of our results.\n",
    "\n",
    "## Data Quality Checks\n",
    "In this stage, we employ a series of tasks designed to identify and address any noise or irregularities within the dataset. Each task focuses on a specific aspect of data quality, ranging from detecting duplicate entries to identifying profanity, special patterns, and other potential sources of bias or distortion.\n",
    "1. **Duplicate Rows**: We identify and remove duplicate entries to ensure that each observation is unique, preventing skewed analyses and inflated metrics.\n",
    "2. **Null Values**: We detect and handle missing data appropriately, which could involve imputation, deletion, or flagging incomplete records for further investigation.\n",
    "3. **Outliers**: Check for outliers in numeric columns using the non-parametric Interquartile Range (IQR) method.\n",
    "4. **Non-English Text**: We check for and address non-English text in reviews and app names, as they may not be relevant to our analysis or could require special handling.\n",
    "5. **Emojis**: Emojis can carry significant meaning in certain contexts but might also introduce noise. We identify and decide on their treatment—whether to retain, remove, or translate them into textual representations.\n",
    "6. **Excessive Special Characters**: Special characters can disrupt text analysis and need to be managed, either by cleaning or encoding them appropriately.\n",
    "7. **Invalid Dates**: We verify that date values fall within expected ranges and formats, correcting or flagging anomalies for further review.\n",
    "8. **Invalid Ratings**: Ratings that fall outside the expected scale (e.g., 1 to 5) are identified and corrected or flagged.\n",
    "9. **Profanity**: We detect and handle profane content to ensure that our dataset adheres to appropriate usage standards, especially if it's intended for public or sensitive applications.\n",
    "10. **Special Patterns**: We identify and manage special patterns such as URLs, phone numbers, and emails. These patterns could be indicative of spam or need to be anonymized to protect privacy.\n",
    "\n",
    "By conducting these data quality checks, we ensure that our dataset is clean, reliable, and ready for detailed analysis. This foundational step sets the stage for accurate insights and robust conclusions in the subsequent phases of our data processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from appinsight.data_prep.dqa import DataQualityAssessment, DQAConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've encapsulated the data quality assessment process in a `DataQualityAssessment` class. Configured with source and target files, this class conducts the 10 data quality checks, marking the observations that require attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "#                        DataQualityAssessment Pipeline                        #\n",
      "# ============================================================================ #\n",
      "\n",
      "Task ReadTask completed successfully. Runtime: 00 Minutes 35.717675 Seconds\n",
      "Task DetectDuplicateRowTask completed successfully. Runtime: 02 Minutes 23.730111 Seconds\n",
      "Task DetectDuplicateRowTask completed successfully. Runtime: 00 Minutes 23.147440 Seconds\n",
      "Task DetectNullValuesTask completed successfully. Runtime: 00 Minutes 06.506046 Seconds\n",
      "Task DetectOutliersTask completed successfully. Runtime: 00 Minutes 01.162850 Seconds\n",
      "Task DetectOutliersTask completed successfully. Runtime: 00 Minutes 01.196009 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:05<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task DetectNonEnglishTask completed successfully. Runtime: 04 Minutes 38.084325 Seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 4040.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task DetectNonEnglishTask completed successfully. Runtime: 02 Minutes 42.454648 Seconds\n",
      "Task DetectEmojiTask completed successfully. Runtime: 01 Minutes 23.527239 Seconds\n",
      "Task DetectSpecialCharacterTask completed successfully. Runtime: 00 Minutes 39.829232 Seconds\n",
      "Task DetectInvalidDatesTask completed successfully. Runtime: 01 Minutes 01.694776 Seconds\n",
      "Task DetectInvalidRatingsTask completed successfully. Runtime: 00 Minutes 09.967982 Seconds\n"
     ]
    }
   ],
   "source": [
    "config = DQAConfig(force=True)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "dqa = DataQualityAssessment(config=config)\n",
    "data = dqa.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a summary of the data quality issues by type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqa.overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Impressions\n",
    "\n",
    "The data quality assessment (DQA) conducted on the AppVoC dataset revealed several key issues that need to be addressed to ensure the integrity and reliability of the analysis. These issues include:\n",
    "\n",
    "- **Duplicates**: A small percentage (<1%) have duplicate review ids.\n",
    "- **Null Values**: Fortunately, there were no null values detected in the dataset.\n",
    "- **Invalid Entries**: There were no invalid dates or invalid ratings found.\n",
    "- **Outliers**: Outliers were identified in vote sums, and vote counts which *could* potentially distort analysis results.\n",
    "- **Non-English**: A notable proportion of the app names (15%) and review content (4.2%) was flagged for being non-English.\n",
    "- **Special Characters**: A small percentage of reviews were noted for the presence of special characters in excessive proportions.\n",
    "- **Profanity & Sensitive Information**: Instances of profanity and the presence of email addresses, URLs, or phone numbers were minimal.\n",
    "\n",
    "Given these findings, the next step is to identify and treat the high-impact data quality issues. This may involve, without limitation:\n",
    "\n",
    "- **Removing Duplicates**: Eliminating observations with duplicate review IDs.\n",
    "- **Handling Outliers**: Identifying and appropriately managing outliers in vote sums, and vote counts.\n",
    "- **Addressing Non-English Text**: Filtering or translating non-English reviews. \n",
    "- **filtering Noise**: Filtering or removing excessive special characters from reviews.\n",
    "- **Ensuring Clean Content**: Censor or remove reviews containing profanity, and personal identifying information such as phone numbers, URLs, and email addresses.\n",
    "\n",
    "Cue the action!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appinsight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
